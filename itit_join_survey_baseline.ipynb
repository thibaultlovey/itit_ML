{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_clean = pd.read_pickle('data_clean/baseline_clean.pkl')\n",
    "survey_clean = pd.read_pickle('data_clean/survey_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "itit_df = pd.merge(baseline_clean, survey_clean, on=['trip_id', 'user_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing surveys\n",
    "def add_missing_surveys(df):\n",
    "    survey_list = []\n",
    "    \n",
    "    for (trip_id, user_id), group in df.groupby(['trip_id', 'user_id']):\n",
    "        travel_date = group['travel_date'].iloc[0]\n",
    "        duration = int(group['travel_duration'].iloc[0])\n",
    "        \n",
    "        # Create a DataFrame with all expected survey dates\n",
    "        all_days = pd.date_range(start=travel_date, periods=duration, freq='D')\n",
    "        existing_days = group['finished'].dt.date.unique()\n",
    "        \n",
    "        # Filter out days that already have surveys\n",
    "        missing_days = [day for day in all_days if day.date() not in existing_days]\n",
    "        \n",
    "        # Create DataFrame for missing surveys\n",
    "        if missing_days:\n",
    "            missing_surveys = pd.DataFrame({\n",
    "                'trip_id': trip_id,\n",
    "                'user_id': user_id,\n",
    "                'travel_date': travel_date,\n",
    "                'finished': pd.to_datetime(missing_days),\n",
    "                'travel_duration': duration\n",
    "            })\n",
    "            \n",
    "            # Copy constant baseline variables\n",
    "            baseline_vars = ['baseline_date', 'age', 'gender', 'country_iso2c', 'country_clean', 'continent_clean', \n",
    "                             'health_chronic', 'latitude', 'longitude', 'smoking_status', 'travel_purpose', 'trip_number']\n",
    "            for var in baseline_vars:\n",
    "                missing_surveys[var] = group[var].iloc[0]\n",
    "                \n",
    "            # Append missing surveys to the list\n",
    "            survey_list.append(missing_surveys)\n",
    "        \n",
    "        # Append existing surveys to the list\n",
    "        survey_list.append(group)\n",
    "    \n",
    "    # Concatenate all DataFrames and sort\n",
    "    df_concat = pd.concat(survey_list).sort_values(by=['trip_id', 'user_id', 'finished']).reset_index(drop=True)\n",
    "\n",
    "    # Ensure finished column is properly filled\n",
    "    df_concat['finished'] = df_concat['finished'].ffill().bfill()\n",
    "\n",
    "    # Ensure no duplicate rows by dropping the extra row caused by the duration miscalculation\n",
    "    df_concat = df_concat.drop_duplicates(subset=['trip_id', 'user_id', 'finished'])\n",
    "    \n",
    "    return df_concat\n",
    "\n",
    "itit_df = add_missing_surveys(itit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only participant that filled at least one survey\n",
    "itit_df_1plus_survey=itit_df.groupby('trip_id').filter(lambda x: x['nausea'].notna().any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filled missing survey based on symptoms length (forward and backward)\n",
    "def fill_columns_forward(data, columns,baselevel, max_repetition=4):\n",
    "    # Loop through each column provided\n",
    "    for column in columns:\n",
    "        # Create a new column to store the filled data\n",
    "        fill_column = f'{column}_filled'\n",
    "        data[fill_column] = data[column].copy()\n",
    "\n",
    "        # Loop through each trip_id\n",
    "        for tid, tdata in data.groupby('trip_id'):\n",
    "            # Sort the grouped data by 'finished' for chronological order\n",
    "            tdata = tdata.sort_values(by='finished')\n",
    "\n",
    "            # We need to work with indices because we look back at previous rows\n",
    "            indices = tdata.index\n",
    "            for i in range(len(indices)):\n",
    "                idx = indices[i]\n",
    "                current_value = tdata.at[idx, column]\n",
    "\n",
    "                if pd.isna(current_value):\n",
    "                    # Look back to count repetitions of the last valid entry if it exists\n",
    "                    last_valid = None\n",
    "                    count_back = 0\n",
    "                    for j in range(1, min(max_repetition, i) + 1):\n",
    "                        back_idx = indices[i - j]\n",
    "                        back_value = tdata.at[back_idx, column]\n",
    "                        if not pd.isna(back_value):\n",
    "                            if last_valid is None:\n",
    "                                last_valid = back_value\n",
    "                            if back_value == last_valid:\n",
    "                                count_back += 1\n",
    "                            else:\n",
    "                                break\n",
    "\n",
    "                    # If the count is less than max_repetition and last_valid is not 'none', fill with last_valid\n",
    "                    if count_back < max_repetition and last_valid != baselevel[column]:\n",
    "                        data.loc[idx, fill_column] = last_valid\n",
    "                else:\n",
    "                    # Update the filled column with current value\n",
    "                    data.loc[idx, fill_column] = current_value\n",
    "\n",
    "    return data\n",
    "\n",
    "def fill_columns_backward(data, columns,baselevel, max_repetition=4):\n",
    "    # Loop through each column provided\n",
    "    for column in columns:\n",
    "        fill_column = f'{column}_filled'\n",
    "        \n",
    "        # Ensure the 'nausea_filled' column exists, copying the original data if not\n",
    "        if fill_column not in data.columns:\n",
    "            data[fill_column] = data[column].copy()\n",
    "\n",
    "        # Loop through each trip_id\n",
    "        for tid, tdata in data.groupby('trip_id'):\n",
    "            # Sort the grouped data by 'finished' in descending order for backward filling\n",
    "            tdata = tdata.sort_values(by='finished', ascending=False)\n",
    "\n",
    "            # We need to work with indices because we look back at previous rows\n",
    "            indices = tdata.index\n",
    "            last_valid = None\n",
    "            count_back = 0\n",
    "            continuous_na = False  # Track if we are in a continuous NA segment\n",
    "\n",
    "            for i in range(len(indices)):\n",
    "                idx = indices[i]\n",
    "                current_value = tdata.at[idx, fill_column]\n",
    "\n",
    "                if pd.isna(current_value):\n",
    "                    if continuous_na:\n",
    "                        # If we are in a continuous NA segment, reset last_valid\n",
    "                        last_valid = None\n",
    "                        count_back = 0\n",
    "                    elif last_valid is not None and last_valid != baselevel[column] and count_back < max_repetition:\n",
    "                        data.loc[idx, fill_column] = last_valid\n",
    "                        count_back += 1\n",
    "                    else:\n",
    "                        # Reset the tracking variables if conditions to fill are not met\n",
    "                        last_valid = None\n",
    "                        count_back = 0\n",
    "                    continuous_na = True  # Mark that we are in a continuous NA segment\n",
    "                else:\n",
    "                    # Reset continuous NA tracking as we hit a non-NA value\n",
    "                    continuous_na = False\n",
    "                    if current_value == last_valid:\n",
    "                        count_back += 1\n",
    "                    else:\n",
    "                        last_valid = current_value\n",
    "                        count_back = 1\n",
    "\n",
    "    return data\n",
    "\n",
    "columns_to_fill = ['nausea', 'vomiting', 'stomach_pain', 'diarrhea',\n",
    "       'constipation','cough', 'sore_throat', 'runny_nose',\n",
    "       'out_of_breath_resting', 'out_of_breath_running','rash',\n",
    "       'itchy_insect_bite', 'itchy_other', 'sunburn', 'itchy_red_eyes','fever', 'dizziness', 'ear_ache', 'headache', 'pain_eyes',\n",
    "       'musle_pain', 'aching_limbs','pain_joint',\n",
    "       'swelling_joint', 'location_swelling',\n",
    "       'body_other',\n",
    "       'impact',\n",
    "       'rating_day'\n",
    "       ]\n",
    "base_level = {\n",
    "    'nausea': 'none',\n",
    "    'vomiting': 'none',\n",
    "    'stomach_pain': 'none',\n",
    "    'diarrhea': 'none',\n",
    "    'constipation': 'none',\n",
    "    'cough': 'none',\n",
    "    'sore_throat': 'none',\n",
    "    'runny_nose': 'none',\n",
    "    'out_of_breath_resting': 'none',\n",
    "    'out_of_breath_running': 'none',\n",
    "    'rash': 'none',\n",
    "    'itchy_insect_bite': 'none',\n",
    "    'itchy_other': 'none',\n",
    "    'sunburn': 'none',\n",
    "    'itchy_red_eyes': 'none',\n",
    "    'fever': 'none',\n",
    "    'dizziness': 'none',\n",
    "    'ear_ache': 'none',\n",
    "    'headache': 'none',\n",
    "    'pain_eyes': 'none',\n",
    "    'musle_pain': 'none',\n",
    "    'aching_limbs': 'none',\n",
    "    'pain_joint': 'none',\n",
    "    'swelling_joint': 'none',\n",
    "    'location_swelling': 'none',\n",
    "    'body_other': 'No',\n",
    "    'impact':'Did not affect my activities',\n",
    "    'rating_day': 'It was a great day'\n",
    "}\n",
    "\n",
    "itit_filled_df = fill_columns_forward(itit_df_1plus_survey, columns_to_fill, baselevel=base_level)\n",
    "itit_filled_df = fill_columns_backward(itit_filled_df, columns_to_fill, baselevel=base_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the filled column names\n",
    "filled_columns = [f'{column}_filled' for column in columns_to_fill]\n",
    "\n",
    "# Adjust the base level mapping to match the filled column names\n",
    "filled_base_level = {f'{column}_filled': base_level[column] for column in columns_to_fill}\n",
    "\n",
    "# Fill NA values based on the adjusted base level mapping\n",
    "itit_filled_df[filled_columns] = itit_filled_df[filled_columns].fillna(filled_base_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_numeric_columns(data, columns, priority='last'):\n",
    "    for column in columns:\n",
    "        fill_column = f'{column}_filled'\n",
    "        data[fill_column] = data[column].copy()\n",
    "\n",
    "        for tid, tdata in data.groupby('trip_id'):\n",
    "            tdata = tdata.sort_values(by='finished')\n",
    "            indices = tdata.index.tolist()\n",
    "            n = len(indices)\n",
    "\n",
    "            I = 0\n",
    "            while I < n:\n",
    "                idx = indices[I]\n",
    "                if pd.isna(tdata.at[idx, column]):\n",
    "                    start_idx = I\n",
    "                    # Find the segment of missing values\n",
    "                    while I < n and pd.isna(tdata.at[indices[I], column]):\n",
    "                        I += 1\n",
    "                    end_idx = I\n",
    "\n",
    "                    # Get the previous and next valid values\n",
    "                    prev_value = tdata.at[indices[start_idx - 1], column] if start_idx > 0 else None\n",
    "                    next_value = tdata.at[indices[end_idx], column] if end_idx < n else None\n",
    "\n",
    "                    # Fill the missing values based on the priority\n",
    "                    num_missing = end_idx - start_idx\n",
    "                    half_point = (num_missing + 1) // 2\n",
    "\n",
    "                    if prev_value is not None and next_value is not None:\n",
    "                        if priority == 'last':\n",
    "                            for j in range(num_missing):\n",
    "                                fill_idx = indices[start_idx + j]\n",
    "                                if j < half_point:\n",
    "                                    data.loc[fill_idx, fill_column] = prev_value\n",
    "                                else:\n",
    "                                    data.loc[fill_idx, fill_column] = next_value\n",
    "                        elif priority == 'first':\n",
    "                            for j in range(num_missing):\n",
    "                                fill_idx = indices[start_idx + j]\n",
    "                                if j < half_point:\n",
    "                                    data.loc[fill_idx, fill_column] = next_value\n",
    "                                else:\n",
    "                                    data.loc[fill_idx, fill_column] = prev_value\n",
    "                    elif prev_value is not None:\n",
    "                        for j in range(num_missing):\n",
    "                            fill_idx = indices[start_idx + j]\n",
    "                            data.loc[fill_idx, fill_column] = prev_value\n",
    "                    elif next_value is not None:\n",
    "                        for j in range(num_missing):\n",
    "                            fill_idx = indices[start_idx + j]\n",
    "                            data.loc[fill_idx, fill_column] = next_value\n",
    "                else:\n",
    "                    I += 1\n",
    "\n",
    "    return data\n",
    "columns_to_fill_numeric = ['trip_id',\n",
    " 'user_id',\n",
    " 'travel_date',\n",
    " 'finished',\n",
    " 'travel_duration',\n",
    " 'baseline_date',\n",
    " 'age',\n",
    " 'gender',\n",
    " 'country_iso2c',\n",
    " 'country_clean',\n",
    " 'continent_clean',\n",
    " 'health_chronic',\n",
    " 'latitude',\n",
    " 'longitude',\n",
    " 'smoking_status',\n",
    " 'travel_purpose',\n",
    " 'trip_number',\n",
    " 'clouds','survey_latitude',\n",
    " 'survey_longitude',\n",
    " 'clouds',\n",
    " 'dew_point',\n",
    " 'feels_like',\n",
    " 'humidity',\n",
    " 'pressure',\n",
    " 'rain_1h',\n",
    " 'snow_1h',\n",
    " 'sunrise',\n",
    " 'sunset',\n",
    " 'temp',\n",
    " 'uvi',\n",
    " 'visibility',\n",
    " 'main_weather',\n",
    " 'description_weather',\n",
    " 'air_quality_components_co',\n",
    " 'air_quality_components_nh_3',\n",
    " 'air_quality_components_no',\n",
    " 'air_quality_components_no_2',\n",
    " 'air_quality_components_o_3',\n",
    " 'air_quality_components_pm_10',\n",
    " 'air_quality_components_pm_2_5',\n",
    " 'air_quality_components_so_2',\n",
    " 'wind_deg',\n",
    " 'wind_gust',\n",
    " 'wind_speed',\n",
    "  'air_quality_main']\n",
    "itit_filled_df = fill_numeric_columns(itit_filled_df, columns_to_fill_numeric, priority='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove initial columns\n",
    "itit_filled_df = itit_filled_df.drop(columns=columns_to_fill)\n",
    "itit_filled_df = itit_filled_df.drop(columns=columns_to_fill_numeric)\n",
    "itit_filled_df = itit_filled_df.drop(columns=['respi_any','gastro_any','skin_any','body_any','joint_any'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat dataset without gps position\n",
    "filled_columns_numeric = [f'{column}_filled' for column in columns_to_fill_numeric[columns_to_fill_numeric.index('clouds'):columns_to_fill_numeric.index('air_quality_main') + 1]]\n",
    "itit_nogps_filled_df = itit_filled_df.copy()\n",
    "itit_nogps_filled_df = itit_nogps_filled_df.drop(columns=filled_columns_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat dataset with gps position\n",
    "itit_filled_df=itit_filled_df.groupby('trip_id_filled').filter(lambda x: x['air_quality_main_filled'].notna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "itit_filled_df[['rain_1h_filled','snow_1h_filled','wind_gust_filled']]=itit_filled_df[['rain_1h_filled','snow_1h_filled','wind_gust_filled']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "itit_nogps_filled_df.to_pickle('data_clean/itit_nogps_filled_df.pkl')\n",
    "itit_filled_df.to_pickle('data_clean/itit_filled_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 22149 entries, 11 to 39345\n",
      "Data columns (total 73 columns):\n",
      " #   Column                                Non-Null Count  Dtype         \n",
      "---  ------                                --------------  -----         \n",
      " 0   nausea_filled                         22149 non-null  object        \n",
      " 1   vomiting_filled                       22149 non-null  object        \n",
      " 2   stomach_pain_filled                   22149 non-null  object        \n",
      " 3   diarrhea_filled                       22149 non-null  object        \n",
      " 4   constipation_filled                   22149 non-null  object        \n",
      " 5   cough_filled                          22149 non-null  object        \n",
      " 6   sore_throat_filled                    22149 non-null  object        \n",
      " 7   runny_nose_filled                     22149 non-null  object        \n",
      " 8   out_of_breath_resting_filled          22149 non-null  object        \n",
      " 9   out_of_breath_running_filled          22149 non-null  object        \n",
      " 10  rash_filled                           22149 non-null  object        \n",
      " 11  itchy_insect_bite_filled              22149 non-null  object        \n",
      " 12  itchy_other_filled                    22149 non-null  object        \n",
      " 13  sunburn_filled                        22149 non-null  object        \n",
      " 14  itchy_red_eyes_filled                 22149 non-null  object        \n",
      " 15  fever_filled                          22149 non-null  object        \n",
      " 16  dizziness_filled                      22149 non-null  object        \n",
      " 17  ear_ache_filled                       22149 non-null  object        \n",
      " 18  headache_filled                       22149 non-null  object        \n",
      " 19  pain_eyes_filled                      22149 non-null  object        \n",
      " 20  musle_pain_filled                     22149 non-null  object        \n",
      " 21  aching_limbs_filled                   22149 non-null  object        \n",
      " 22  pain_joint_filled                     22149 non-null  object        \n",
      " 23  swelling_joint_filled                 22149 non-null  object        \n",
      " 24  location_swelling_filled              22149 non-null  object        \n",
      " 25  body_other_filled                     22149 non-null  object        \n",
      " 26  impact_filled                         22149 non-null  object        \n",
      " 27  rating_day_filled                     22149 non-null  object        \n",
      " 28  trip_id_filled                        22149 non-null  object        \n",
      " 29  user_id_filled                        22149 non-null  object        \n",
      " 30  travel_date_filled                    22149 non-null  datetime64[ns]\n",
      " 31  finished_filled                       22149 non-null  datetime64[ns]\n",
      " 32  travel_duration_filled                22149 non-null  float64       \n",
      " 33  baseline_date_filled                  22149 non-null  datetime64[ns]\n",
      " 34  age_filled                            22149 non-null  float64       \n",
      " 35  gender_filled                         22066 non-null  object        \n",
      " 36  country_iso2c_filled                  22149 non-null  object        \n",
      " 37  country_clean_filled                  16111 non-null  object        \n",
      " 38  continent_clean_filled                22128 non-null  object        \n",
      " 39  health_chronic_filled                 22149 non-null  object        \n",
      " 40  latitude_filled                       20115 non-null  float64       \n",
      " 41  longitude_filled                      20115 non-null  float64       \n",
      " 42  smoking_status_filled                 22120 non-null  object        \n",
      " 43  travel_purpose_filled                 22149 non-null  object        \n",
      " 44  trip_number_filled                    22149 non-null  object        \n",
      " 45  clouds_filled                         22149 non-null  float64       \n",
      " 46  survey_latitude_filled                22149 non-null  float64       \n",
      " 47  survey_longitude_filled               22149 non-null  float64       \n",
      " 48  dew_point_filled                      22149 non-null  float64       \n",
      " 49  feels_like_filled                     22149 non-null  float64       \n",
      " 50  humidity_filled                       22149 non-null  float64       \n",
      " 51  pressure_filled                       22149 non-null  float64       \n",
      " 52  rain_1h_filled                        22149 non-null  float64       \n",
      " 53  snow_1h_filled                        22149 non-null  float64       \n",
      " 54  sunrise_filled                        22149 non-null  float64       \n",
      " 55  sunset_filled                         22149 non-null  float64       \n",
      " 56  temp_filled                           22149 non-null  float64       \n",
      " 57  uvi_filled                            22149 non-null  float64       \n",
      " 58  visibility_filled                     22149 non-null  float64       \n",
      " 59  main_weather_filled                   22149 non-null  object        \n",
      " 60  description_weather_filled            22149 non-null  object        \n",
      " 61  air_quality_components_co_filled      22149 non-null  float64       \n",
      " 62  air_quality_components_nh_3_filled    22149 non-null  float64       \n",
      " 63  air_quality_components_no_filled      22149 non-null  float64       \n",
      " 64  air_quality_components_no_2_filled    22149 non-null  float64       \n",
      " 65  air_quality_components_o_3_filled     22149 non-null  float64       \n",
      " 66  air_quality_components_pm_10_filled   22149 non-null  float64       \n",
      " 67  air_quality_components_pm_2_5_filled  22149 non-null  float64       \n",
      " 68  air_quality_components_so_2_filled    22149 non-null  float64       \n",
      " 69  wind_deg_filled                       22149 non-null  float64       \n",
      " 70  wind_gust_filled                      22149 non-null  float64       \n",
      " 71  wind_speed_filled                     22149 non-null  float64       \n",
      " 72  air_quality_main_filled               22149 non-null  object        \n",
      "dtypes: datetime64[ns](3), float64(29), object(41)\n",
      "memory usage: 12.5+ MB\n"
     ]
    }
   ],
   "source": [
    "itit_filled_df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
