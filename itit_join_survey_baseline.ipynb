{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_clean = pd.read_pickle('data_clean/baseline_clean.pkl')\n",
    "survey_clean = pd.read_pickle('data_clean/survey_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "itit_df = pd.merge(baseline_clean, survey_clean, on=['trip_id', 'user_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing surveys\n",
    "def add_missing_surveys(df):\n",
    "    survey_list = []\n",
    "    \n",
    "    for (trip_id, user_id), group in df.groupby(['trip_id', 'user_id']):\n",
    "        travel_date = group['travel_date'].iloc[0]\n",
    "        duration = int(group['travel_duration'].iloc[0])\n",
    "        \n",
    "        # Create a DataFrame with all expected survey dates\n",
    "        all_days = pd.date_range(start=travel_date, periods=duration, freq='D')\n",
    "        existing_days = group['finished'].dt.date.unique()\n",
    "        \n",
    "        # Filter out days that already have surveys\n",
    "        missing_days = [day for day in all_days if day.date() not in existing_days]\n",
    "        \n",
    "        # Create DataFrame for missing surveys\n",
    "        if missing_days:\n",
    "            missing_surveys = pd.DataFrame({\n",
    "                'trip_id': trip_id,\n",
    "                'user_id': user_id,\n",
    "                'travel_date': travel_date,\n",
    "                'finished': pd.to_datetime(missing_days),\n",
    "                'travel_duration': duration\n",
    "            })\n",
    "            \n",
    "            # Copy constant baseline variables\n",
    "            baseline_vars = ['baseline_date', 'age', 'gender', 'country_iso2c', 'country_clean', 'continent_clean', \n",
    "                             'health_chronic', 'latitude', 'longitude', 'smoking_status', 'travel_purpose', 'trip_number']\n",
    "            for var in baseline_vars:\n",
    "                missing_surveys[var] = group[var].iloc[0]\n",
    "                \n",
    "            # Append missing surveys to the list\n",
    "            survey_list.append(missing_surveys)\n",
    "        \n",
    "        # Append existing surveys to the list\n",
    "        survey_list.append(group)\n",
    "    \n",
    "    # Concatenate all DataFrames and sort\n",
    "    df_concat = pd.concat(survey_list).sort_values(by=['trip_id', 'user_id', 'finished']).reset_index(drop=True)\n",
    "\n",
    "    # Ensure finished column is properly filled\n",
    "    df_concat['finished'] = df_concat['finished'].ffill().bfill()\n",
    "\n",
    "    # Ensure no duplicate rows by dropping the extra row caused by the duration miscalculation\n",
    "    df_concat = df_concat.drop_duplicates(subset=['trip_id', 'user_id', 'finished'])\n",
    "    \n",
    "    return df_concat\n",
    "\n",
    "itit_df = add_missing_surveys(itit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only participant that filled at least one survey\n",
    "itit_df_1plus_survey=itit_df.groupby('trip_id').filter(lambda x: x['nausea'].notna().any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filled missing survey based on symptoms length (forward and backward)\n",
    "def fill_columns_forward(data, columns,baselevel, max_repetition=4):\n",
    "    # Loop through each column provided\n",
    "    for column in columns:\n",
    "        # Create a new column to store the filled data\n",
    "        fill_column = f'{column}_filled'\n",
    "        data[fill_column] = data[column].copy()\n",
    "\n",
    "        # Loop through each trip_id\n",
    "        for tid, tdata in data.groupby('trip_id'):\n",
    "            # Sort the grouped data by 'finished' for chronological order\n",
    "            tdata = tdata.sort_values(by='finished')\n",
    "\n",
    "            # We need to work with indices because we look back at previous rows\n",
    "            indices = tdata.index\n",
    "            for i in range(len(indices)):\n",
    "                idx = indices[i]\n",
    "                current_value = tdata.at[idx, column]\n",
    "\n",
    "                if pd.isna(current_value):\n",
    "                    # Look back to count repetitions of the last valid entry if it exists\n",
    "                    last_valid = None\n",
    "                    count_back = 0\n",
    "                    for j in range(1, min(max_repetition, i) + 1):\n",
    "                        back_idx = indices[i - j]\n",
    "                        back_value = tdata.at[back_idx, column]\n",
    "                        if not pd.isna(back_value):\n",
    "                            if last_valid is None:\n",
    "                                last_valid = back_value\n",
    "                            if back_value == last_valid:\n",
    "                                count_back += 1\n",
    "                            else:\n",
    "                                break\n",
    "\n",
    "                    # If the count is less than max_repetition and last_valid is not 'none', fill with last_valid\n",
    "                    if count_back < max_repetition and last_valid != baselevel[column]:\n",
    "                        data.loc[idx, fill_column] = last_valid\n",
    "                else:\n",
    "                    # Update the filled column with current value\n",
    "                    data.loc[idx, fill_column] = current_value\n",
    "\n",
    "    return data\n",
    "\n",
    "def fill_columns_backward(data, columns,baselevel, max_repetition=4):\n",
    "    # Loop through each column provided\n",
    "    for column in columns:\n",
    "        fill_column = f'{column}_filled'\n",
    "        \n",
    "        # Ensure the 'nausea_filled' column exists, copying the original data if not\n",
    "        if fill_column not in data.columns:\n",
    "            data[fill_column] = data[column].copy()\n",
    "\n",
    "        # Loop through each trip_id\n",
    "        for tid, tdata in data.groupby('trip_id'):\n",
    "            # Sort the grouped data by 'finished' in descending order for backward filling\n",
    "            tdata = tdata.sort_values(by='finished', ascending=False)\n",
    "\n",
    "            # We need to work with indices because we look back at previous rows\n",
    "            indices = tdata.index\n",
    "            last_valid = None\n",
    "            count_back = 0\n",
    "            continuous_na = False  # Track if we are in a continuous NA segment\n",
    "\n",
    "            for i in range(len(indices)):\n",
    "                idx = indices[i]\n",
    "                current_value = tdata.at[idx, fill_column]\n",
    "\n",
    "                if pd.isna(current_value):\n",
    "                    if continuous_na:\n",
    "                        # If we are in a continuous NA segment, reset last_valid\n",
    "                        last_valid = None\n",
    "                        count_back = 0\n",
    "                    elif last_valid is not None and last_valid != baselevel[column] and count_back < max_repetition:\n",
    "                        data.loc[idx, fill_column] = last_valid\n",
    "                        count_back += 1\n",
    "                    else:\n",
    "                        # Reset the tracking variables if conditions to fill are not met\n",
    "                        last_valid = None\n",
    "                        count_back = 0\n",
    "                    continuous_na = True  # Mark that we are in a continuous NA segment\n",
    "                else:\n",
    "                    # Reset continuous NA tracking as we hit a non-NA value\n",
    "                    continuous_na = False\n",
    "                    if current_value == last_valid:\n",
    "                        count_back += 1\n",
    "                    else:\n",
    "                        last_valid = current_value\n",
    "                        count_back = 1\n",
    "\n",
    "    return data\n",
    "\n",
    "columns_to_fill = ['nausea', 'vomiting', 'stomach_pain', 'diarrhea',\n",
    "       'constipation','cough', 'sore_throat', 'runny_nose',\n",
    "       'out_of_breath_resting', 'out_of_breath_running','rash',\n",
    "       'itchy_insect_bite', 'itchy_other', 'sunburn', 'itchy_red_eyes','fever', 'dizziness', 'ear_ache', 'headache', 'pain_eyes',\n",
    "       'musle_pain', 'aching_limbs','pain_joint',\n",
    "       'swelling_joint', 'location_swelling',\n",
    "       'body_other',\n",
    "       'impact',\n",
    "       'rating_day'\n",
    "       ]\n",
    "base_level = {\n",
    "    'nausea': 'none',\n",
    "    'vomiting': 'none',\n",
    "    'stomach_pain': 'none',\n",
    "    'diarrhea': 'none',\n",
    "    'constipation': 'none',\n",
    "    'cough': 'none',\n",
    "    'sore_throat': 'none',\n",
    "    'runny_nose': 'none',\n",
    "    'out_of_breath_resting': 'none',\n",
    "    'out_of_breath_running': 'none',\n",
    "    'rash': 'none',\n",
    "    'itchy_insect_bite': 'none',\n",
    "    'itchy_other': 'none',\n",
    "    'sunburn': 'none',\n",
    "    'itchy_red_eyes': 'none',\n",
    "    'fever': 'none',\n",
    "    'dizziness': 'none',\n",
    "    'ear_ache': 'none',\n",
    "    'headache': 'none',\n",
    "    'pain_eyes': 'none',\n",
    "    'musle_pain': 'none',\n",
    "    'aching_limbs': 'none',\n",
    "    'pain_joint': 'none',\n",
    "    'swelling_joint': 'none',\n",
    "    'location_swelling': 'none',\n",
    "    'body_other': 'No',\n",
    "    'impact':'Did not affect my activities',\n",
    "    'rating_day': 'It was a great day'\n",
    "}\n",
    "\n",
    "itit_filled_df = fill_columns_forward(itit_df_1plus_survey, columns_to_fill, baselevel=base_level)\n",
    "itit_filled_df = fill_columns_backward(itit_filled_df, columns_to_fill, baselevel=base_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the filled column names\n",
    "filled_columns = [f'{column}_filled' for column in columns_to_fill]\n",
    "\n",
    "# Adjust the base level mapping to match the filled column names\n",
    "filled_base_level = {f'{column}_filled': base_level[column] for column in columns_to_fill}\n",
    "\n",
    "# Fill NA values based on the adjusted base level mapping\n",
    "itit_filled_df[filled_columns] = itit_filled_df[filled_columns].fillna(filled_base_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['trip_id', 'user_id', 'travel_date', 'finished', 'travel_duration',\n",
       "       'baseline_date', 'age', 'gender', 'country_iso2c', 'country_clean',\n",
       "       ...\n",
       "       'headache_filled', 'pain_eyes_filled', 'musle_pain_filled',\n",
       "       'aching_limbs_filled', 'pain_joint_filled', 'swelling_joint_filled',\n",
       "       'location_swelling_filled', 'body_other_filled', 'impact_filled',\n",
       "       'rating_day_filled'],\n",
       "      dtype='object', length=109)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itit_filled_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_numeric_columns(data, columns, priority='last'):\n",
    "    for column in columns:\n",
    "        fill_column = f'{column}_filled'\n",
    "        data[fill_column] = data[column].copy()\n",
    "\n",
    "        for tid, tdata in data.groupby('trip_id'):\n",
    "            tdata = tdata.sort_values(by='finished')\n",
    "            indices = tdata.index.tolist()\n",
    "            n = len(indices)\n",
    "\n",
    "            i = 0\n",
    "            while i < n:\n",
    "                idx = indices[i]\n",
    "                if pd.isna(tdata.at[idx, column]):\n",
    "                    start_idx = i\n",
    "                    # Find the segment of missing values\n",
    "                    while i < n and pd.isna(tdata.at[indices[i], column]):\n",
    "                        i += 1\n",
    "                    end_idx = i\n",
    "\n",
    "                    # Get the previous and next valid values\n",
    "                    prev_value = tdata.at[indices[start_idx - 1], column] if start_idx > 0 else None\n",
    "                    next_value = tdata.at[indices[end_idx], column] if end_idx < n else None\n",
    "\n",
    "                    # Fill the missing values based on the priority\n",
    "                    num_missing = end_idx - start_idx\n",
    "                    half_point = (num_missing + 1) // 2\n",
    "\n",
    "                    if prev_value is not None and next_value is not None:\n",
    "                        for j in range(num_missing):\n",
    "                            fill_idx = indices[start_idx + j]\n",
    "                            if j < half_point:\n",
    "                                data.loc[fill_idx, fill_column] = prev_value\n",
    "                            else:\n",
    "                                data.loc[fill_idx, fill_column] = next_value\n",
    "                    elif prev_value is not None:\n",
    "                        for j in range(num_missing):\n",
    "                            fill_idx = indices[start_idx + j]\n",
    "                            data.loc[fill_idx, fill_column] = prev_value\n",
    "                    elif next_value is not None:\n",
    "                        for j in range(num_missing):\n",
    "                            fill_idx = indices[start_idx + j]\n",
    "                            data.loc[fill_idx, fill_column] = next_value\n",
    "                else:\n",
    "                    i += 1\n",
    "\n",
    "    return data\n",
    "\n",
    "columns_to_fill_numeric = ['clouds']\n",
    "\n",
    "itit_filled_df_test = fill_numeric_columns(itit_df_1plus_survey, columns_to_fill_numeric, priority='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=itit_filled_df_test[['trip_id','finished','clouds','clouds_filled']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
