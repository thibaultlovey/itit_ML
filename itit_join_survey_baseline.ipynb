{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_clean = pd.read_pickle('data_clean/baseline_clean.pkl')\n",
    "survey_clean = pd.read_pickle('data_clean/survey_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "itit_df = pd.merge(baseline_clean, survey_clean, on=['trip_id', 'user_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_surveys(df):\n",
    "    survey_list = []\n",
    "    \n",
    "    for (trip_id, user_id), group in df.groupby(['trip_id', 'user_id']):\n",
    "        travel_date = group['travel_date'].iloc[0]\n",
    "        duration = int(group['travel_duration'].iloc[0])\n",
    "        \n",
    "        # Create a DataFrame with all expected survey dates\n",
    "        all_days = pd.date_range(start=travel_date, periods=duration, freq='D')\n",
    "        existing_days = group['finished'].dt.date.unique()\n",
    "        \n",
    "        # Filter out days that already have surveys\n",
    "        missing_days = [day for day in all_days if day.date() not in existing_days]\n",
    "        \n",
    "        # Create DataFrame for missing surveys\n",
    "        if missing_days:\n",
    "            missing_surveys = pd.DataFrame({\n",
    "                'trip_id': trip_id,\n",
    "                'user_id': user_id,\n",
    "                'travel_date': travel_date,\n",
    "                'finished': pd.to_datetime(missing_days),\n",
    "                'travel_duration': duration\n",
    "            })\n",
    "            \n",
    "            # Copy constant baseline variables\n",
    "            baseline_vars = ['baseline_date', 'age', 'gender', 'country_iso2c', 'country_clean', 'continent_clean', \n",
    "                             'health_chronic', 'latitude', 'longitude', 'smoking_status', 'travel_purpose', 'trip_number']\n",
    "            for var in baseline_vars:\n",
    "                missing_surveys[var] = group[var].iloc[0]\n",
    "                \n",
    "            # Append missing surveys to the list\n",
    "            survey_list.append(missing_surveys)\n",
    "        \n",
    "        # Append existing surveys to the list\n",
    "        survey_list.append(group)\n",
    "    \n",
    "    # Concatenate all DataFrames and sort\n",
    "    df_concat = pd.concat(survey_list).sort_values(by=['trip_id', 'user_id', 'finished']).reset_index(drop=True)\n",
    "\n",
    "    # Ensure finished column is properly filled\n",
    "    df_concat['finished'] = df_concat['finished'].ffill().bfill()\n",
    "\n",
    "    # Ensure no duplicate rows by dropping the extra row caused by the duration miscalculation\n",
    "    df_concat = df_concat.drop_duplicates(subset=['trip_id', 'user_id', 'finished'])\n",
    "    \n",
    "    return df_concat\n",
    "\n",
    "# Add missing surveys\n",
    "itit_df = add_missing_surveys(itit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only participant that filled at least one survey\n",
    "itit_df_1plus_survey=itit_df.groupby('trip_id').filter(lambda x: x['nausea'].notna().any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_columns_forward(data, columns, max_repetition=4):\n",
    "    # Loop through each column provided\n",
    "    for column in columns:\n",
    "        # Create a new column to store the filled data\n",
    "        fill_column = f'{column}_filled'\n",
    "        data[fill_column] = data[column].copy()\n",
    "\n",
    "        # Loop through each trip_id\n",
    "        for tid, tdata in data.groupby('trip_id'):\n",
    "            # Sort the grouped data by 'finished' for chronological order\n",
    "            tdata = tdata.sort_values(by='finished')\n",
    "\n",
    "            # We need to work with indices because we look back at previous rows\n",
    "            indices = tdata.index\n",
    "            for i in range(len(indices)):\n",
    "                idx = indices[i]\n",
    "                current_value = tdata.at[idx, column]\n",
    "\n",
    "                if pd.isna(current_value):\n",
    "                    # Look back to count repetitions of the last valid entry if it exists\n",
    "                    last_valid = None\n",
    "                    count_back = 0\n",
    "                    for j in range(1, min(max_repetition, i) + 1):\n",
    "                        back_idx = indices[i - j]\n",
    "                        back_value = tdata.at[back_idx, column]\n",
    "                        if not pd.isna(back_value):\n",
    "                            if last_valid is None:\n",
    "                                last_valid = back_value\n",
    "                            if back_value == last_valid:\n",
    "                                count_back += 1\n",
    "                            else:\n",
    "                                break\n",
    "\n",
    "                    # If the count is less than max_repetition and last_valid is not 'none', fill with last_valid\n",
    "                    if count_back < max_repetition and last_valid != 'none':\n",
    "                        data.loc[idx, fill_column] = last_valid\n",
    "                else:\n",
    "                    # Update the filled column with current value\n",
    "                    data.loc[idx, fill_column] = current_value\n",
    "\n",
    "    return data\n",
    "\n",
    "def fill_columns_backward(data, columns, max_repetition=4):\n",
    "    # Loop through each column provided\n",
    "    for column in columns:\n",
    "        fill_column = f'{column}_filled'\n",
    "        \n",
    "        # Ensure the 'nausea_filled' column exists, copying the original data if not\n",
    "        if fill_column not in data.columns:\n",
    "            data[fill_column] = data[column].copy()\n",
    "\n",
    "        # Loop through each trip_id\n",
    "        for tid, tdata in data.groupby('trip_id'):\n",
    "            # Sort the grouped data by 'finished' in descending order for backward filling\n",
    "            tdata = tdata.sort_values(by='finished', ascending=False)\n",
    "\n",
    "            # We need to work with indices because we look back at previous rows\n",
    "            indices = tdata.index\n",
    "            last_valid = None\n",
    "            count_back = 0\n",
    "            continuous_na = False  # Track if we are in a continuous NA segment\n",
    "\n",
    "            for i in range(len(indices)):\n",
    "                idx = indices[i]\n",
    "                current_value = tdata.at[idx, fill_column]\n",
    "\n",
    "                if pd.isna(current_value):\n",
    "                    if continuous_na:\n",
    "                        # If we are in a continuous NA segment, reset last_valid\n",
    "                        last_valid = None\n",
    "                        count_back = 0\n",
    "                    elif last_valid is not None and last_valid != 'none' and count_back < max_repetition:\n",
    "                        data.loc[idx, fill_column] = last_valid\n",
    "                        count_back += 1\n",
    "                    else:\n",
    "                        # Reset the tracking variables if conditions to fill are not met\n",
    "                        last_valid = None\n",
    "                        count_back = 0\n",
    "                    continuous_na = True  # Mark that we are in a continuous NA segment\n",
    "                else:\n",
    "                    # Reset continuous NA tracking as we hit a non-NA value\n",
    "                    continuous_na = False\n",
    "                    if current_value == last_valid:\n",
    "                        count_back += 1\n",
    "                    else:\n",
    "                        last_valid = current_value\n",
    "                        count_back = 1\n",
    "\n",
    "    return data\n",
    "\n",
    "columns_to_fill = ['nausea', 'vomiting', 'stomach_pain', 'diarrhea',\n",
    "       'constipation','cough', 'sore_throat', 'runny_nose',\n",
    "       'out_of_breath_resting', 'out_of_breath_running','rash',\n",
    "       'itchy_insect_bite', 'itchy_other', 'sunburn', 'itchy_red_eyes','fever', 'dizziness', 'ear_ache', 'headache', 'pain_eyes',\n",
    "       'musle_pain', 'aching_limbs','pain_joint',\n",
    "       'swelling_joint', 'location_swelling']\n",
    "filled_df = fill_columns_forward(itit_df_1plus_survey, columns_to_fill)\n",
    "filled_df = fill_columns_backward(filled_df, columns_to_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_df[columns_to_fill] = filled_df[columns_to_fill].fillna('none')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
